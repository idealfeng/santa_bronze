{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":119106,"databundleVersionId":14485445,"sourceType":"competition"},{"sourceId":288709509,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":385.341625,"end_time":"2025-12-20T13:54:29.248659","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-20T13:48:03.907034","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q shapely","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T09:22:11.115832Z","iopub.execute_input":"2025-12-23T09:22:11.116093Z","iopub.status.idle":"2025-12-23T09:22:12.111334Z","shell.execute_reply.started":"2025-12-23T09:22:11.116068Z","shell.execute_reply":"2025-12-23T09:22:12.110232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# 3-HOUR FAST IMPROVEMENT RUNNER (bbox3 + smart filtering)\n# - Coarse short runs to find promising (n,r)\n# - Only runs expensive fix_direction + overlap validation on winners\n# - Escalates timeout only for top candidates\n# - Keeps best submission; reverts on regressions\n# ============================================================\n\nimport os\nimport re\nimport csv\nimport time\nimport shutil\nimport subprocess\nfrom glob import glob\nfrom datetime import datetime\nfrom decimal import Decimal, getcontext\nfrom zipfile import ZipFile, ZIP_DEFLATED\n\nimport numpy as np\nimport pandas as pd\n\nfrom shapely import affinity\nfrom shapely.geometry import Polygon\nfrom shapely.ops import unary_union\nfrom shapely.strtree import STRtree\n\nfrom scipy.spatial import ConvexHull\nfrom scipy.optimize import minimize_scalar\n\n\n# ----------------------------\n# USER CONFIG\n# ----------------------------\nBASELINE_CSV = \"/kaggle/input/santa-submission/submission.csv\"\nBBOX3_BIN_IN = \"/kaggle/input/santa-submission/bbox3\"\n\nWORK_SUBMISSION = \"submission.csv\"\nWORK_BBOX3_BIN = \"./bbox3\"\n\nOUT_DIR = \"fast3h_out\"\nLOG_FILE = \"fast3h.log\"\n\nTOTAL_BUDGET_SEC = 3 * 3600  # 3 hours hard budget (wall time)\n\n# Only accept a candidate if it beats current best by at least this much.\n# Increase if you want fewer expensive validations.\nMIN_IMPROVEMENT_TO_PROCESS = 1e-10\n\n# Rotation tightening controls (cheap-ish, but not free)\nROT_EPSILON = 1e-7\nROT_ANGLE_MAX = 89.999\nROT_GROUP_MAX = 200\n\n# Decimal precision\ngetcontext().prec = 30\nscale_factor = Decimal(\"1\")\n\n\n# ============================================================\n# Core geometry model + scoring (grounded in your snippet)\n# ============================================================\n\nclass ChristmasTree:\n    def __init__(self, center_x=\"0\", center_y=\"0\", angle=\"0\"):\n        self.center_x = Decimal(str(center_x))\n        self.center_y = Decimal(str(center_y))\n        self.angle = Decimal(str(angle))\n\n        trunk_w = Decimal(\"0.15\")\n        trunk_h = Decimal(\"0.2\")\n        base_w = Decimal(\"0.7\")\n        mid_w  = Decimal(\"0.4\")\n        top_w  = Decimal(\"0.25\")\n        tip_y = Decimal(\"0.8\")\n        tier_1_y = Decimal(\"0.5\")\n        tier_2_y = Decimal(\"0.25\")\n        base_y = Decimal(\"0.0\")\n        trunk_bottom_y = -trunk_h\n\n        initial_polygon = Polygon(\n            [\n                (Decimal(\"0.0\") * scale_factor, tip_y * scale_factor),\n                (top_w / Decimal(\"2\") * scale_factor, tier_1_y * scale_factor),\n                (top_w / Decimal(\"4\") * scale_factor, tier_1_y * scale_factor),\n                (mid_w / Decimal(\"2\") * scale_factor, tier_2_y * scale_factor),\n                (mid_w / Decimal(\"4\") * scale_factor, tier_2_y * scale_factor),\n                (base_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n                (trunk_w / Decimal(\"2\") * scale_factor, base_y * scale_factor),\n                (trunk_w / Decimal(\"2\") * scale_factor, trunk_bottom_y * scale_factor),\n                (-(trunk_w / Decimal(\"2\")) * scale_factor, trunk_bottom_y * scale_factor),\n                (-(trunk_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n                (-(base_w / Decimal(\"2\")) * scale_factor, base_y * scale_factor),\n                (-(mid_w / Decimal(\"4\")) * scale_factor, tier_2_y * scale_factor),\n                (-(mid_w / Decimal(\"2\")) * scale_factor, tier_2_y * scale_factor),\n                (-(top_w / Decimal(\"4\")) * scale_factor, tier_1_y * scale_factor),\n                (-(top_w / Decimal(\"2\")) * scale_factor, tier_1_y * scale_factor),\n            ]\n        )\n\n        rotated = affinity.rotate(initial_polygon, float(self.angle), origin=(0, 0))\n        self.polygon = affinity.translate(\n            rotated,\n            xoff=float(self.center_x * scale_factor),\n            yoff=float(self.center_y * scale_factor),\n        )\n\n    def clone(self):\n        return ChristmasTree(center_x=str(self.center_x), center_y=str(self.center_y), angle=str(self.angle))\n\n\ndef get_tree_list_side_lenght(tree_list):\n    all_polygons = [t.polygon for t in tree_list]\n    bounds = unary_union(all_polygons).bounds\n    return Decimal(max(bounds[2] - bounds[0], bounds[3] - bounds[1])) / scale_factor\n\n\ndef get_total_score(dict_of_side_length):\n    score = Decimal(\"0\")\n    for k, v in dict_of_side_length.items():\n        score += v ** 2 / Decimal(str(k))\n    return score\n\n\ndef parse_csv(csv_path):\n    df = pd.read_csv(csv_path)\n\n    # strip 's' prefix (matches your snippet)\n    df[\"x\"] = df[\"x\"].astype(str).str.strip().str.lstrip(\"s\")\n    df[\"y\"] = df[\"y\"].astype(str).str.strip().str.lstrip(\"s\")\n    df[\"deg\"] = df[\"deg\"].astype(str).str.strip().str.lstrip(\"s\")\n    df[[\"group_id\", \"item_id\"]] = df[\"id\"].str.split(\"_\", n=2, expand=True)\n\n    dict_of_tree_list = {}\n    dict_of_side_length = {}\n\n    for group_id, group_data in df.groupby(\"group_id\"):\n        tree_list = [\n            ChristmasTree(center_x=row[\"x\"], center_y=row[\"y\"], angle=row[\"deg\"])\n            for _, row in group_data.iterrows()\n        ]\n        dict_of_tree_list[group_id] = tree_list\n        dict_of_side_length[group_id] = get_tree_list_side_lenght(tree_list)\n\n    return dict_of_tree_list, dict_of_side_length\n\n\n# ============================================================\n# Rotation tightening (fix_direction), grounded in your snippet\n# ============================================================\n\ndef calculate_bbox_side_at_angle(angle_deg, points):\n    angle_rad = np.radians(angle_deg)\n    c, s = np.cos(angle_rad), np.sin(angle_rad)\n    rot_matrix_T = np.array([[c, s], [-s, c]])\n    rotated_points = points.dot(rot_matrix_T)\n    min_xy = np.min(rotated_points, axis=0)\n    max_xy = np.max(rotated_points, axis=0)\n    return max(max_xy[0] - min_xy[0], max_xy[1] - min_xy[1])\n\n\ndef optimize_rotation(trees, angle_max=ROT_ANGLE_MAX, epsilon=ROT_EPSILON):\n    all_points = []\n    for tree in trees:\n        all_points.extend(list(tree.polygon.exterior.coords))\n    points_np = np.array(all_points)\n\n    hull_points = points_np[ConvexHull(points_np).vertices]\n    initial_side = calculate_bbox_side_at_angle(0, hull_points)\n\n    res = minimize_scalar(\n        lambda a: calculate_bbox_side_at_angle(a, hull_points),\n        bounds=(0.001, float(angle_max)),\n        method=\"bounded\",\n    )\n\n    found_angle_deg = float(res.x)\n    found_side = float(res.fun)\n\n    improvement = initial_side - found_side\n    if improvement > float(epsilon):\n        best_angle_deg = found_angle_deg\n        best_side = Decimal(str(found_side)) / scale_factor\n    else:\n        best_angle_deg = 0.0\n        best_side = Decimal(str(initial_side)) / scale_factor\n\n    return best_side, best_angle_deg\n\n\ndef apply_rotation(trees, angle_deg):\n    if not trees or abs(angle_deg) < 1e-12:\n        return [t.clone() for t in trees]\n\n    bounds = [t.polygon.bounds for t in trees]\n    min_x = min(b[0] for b in bounds)\n    min_y = min(b[1] for b in bounds)\n    max_x = max(b[2] for b in bounds)\n    max_y = max(b[3] for b in bounds)\n    rotation_center = np.array([(min_x + max_x) / 2.0, (min_y + max_y) / 2.0])\n\n    angle_rad = np.radians(angle_deg)\n    c, s = np.cos(angle_rad), np.sin(angle_rad)\n    rot_matrix = np.array([[c, -s], [s, c]])\n\n    points = np.array([[float(t.center_x), float(t.center_y)] for t in trees])\n    shifted = points - rotation_center\n    rotated = shifted.dot(rot_matrix.T) + rotation_center\n\n    rotated_trees = []\n    for i in range(len(trees)):\n        new_tree = ChristmasTree(\n            Decimal(rotated[i, 0]),\n            Decimal(rotated[i, 1]),\n            Decimal(trees[i].angle + Decimal(str(angle_deg))),\n        )\n        rotated_trees.append(new_tree)\n\n    return rotated_trees\n\n\ndef write_submission(dict_of_tree_list, out_file):\n    rows = []\n    for group_name, tree_list in dict_of_tree_list.items():\n        for item_id, tree in enumerate(tree_list):\n            rows.append(\n                {\n                    \"id\": f\"{group_name}_{item_id}\",\n                    \"x\": f\"s{tree.center_x}\",\n                    \"y\": f\"s{tree.center_y}\",\n                    \"deg\": f\"s{tree.angle}\",\n                }\n            )\n    pd.DataFrame(rows).to_csv(out_file, index=False)\n\n\ndef fix_direction(in_csv, out_csv, passes=1):\n    dict_of_tree_list, dict_of_side_length = parse_csv(in_csv)\n    current_score = get_total_score(dict_of_side_length)\n\n    for _ in range(int(passes)):\n        changed = False\n        for group_id_main in range(ROT_GROUP_MAX, 2, -1):\n            gid = f\"{int(group_id_main):03d}\"\n            if gid not in dict_of_tree_list:\n                continue\n\n            trees = dict_of_tree_list[gid]\n            best_side, best_angle_deg = optimize_rotation(trees)\n            if best_side < dict_of_side_length[gid]:\n                dict_of_tree_list[gid] = apply_rotation(trees, best_angle_deg)\n                dict_of_side_length[gid] = best_side\n                changed = True\n\n        new_score = get_total_score(dict_of_side_length)\n        if new_score >= current_score or not changed:\n            current_score = new_score\n            break\n        current_score = new_score\n\n    write_submission(dict_of_tree_list, out_csv)\n    return float(current_score)\n\n\n# ============================================================\n# Overlap check + targeted repair (grounded in your snippet)\n# ============================================================\n\ndef has_overlap(trees):\n    if len(trees) <= 1:\n        return False\n\n    polygons = [t.polygon for t in trees]\n    tree_index = STRtree(polygons)\n\n    for i, poly in enumerate(polygons):\n        candidates = tree_index.query(poly)\n\n        for cand in candidates:\n            # Shapely 2.x may return indices, Shapely 1.8 may return geometries\n            if isinstance(cand, (int, np.integer)):\n                j = int(cand)\n                if j == i:\n                    continue\n                other = polygons[j]\n            else:\n                if cand is poly:\n                    continue\n                other = cand\n\n            if poly.intersects(other) and not poly.touches(other):\n                return True\n\n    return False\n\n\ndef score_and_validate_submission(file_path, max_n=ROT_GROUP_MAX):\n    dict_of_tree_list, dict_of_side_length = parse_csv(file_path)\n\n    failed = []\n    for n in range(1, max_n + 1):\n        gid = f\"{n:03d}\"\n        trees = dict_of_tree_list.get(gid)\n        if not trees:\n            continue\n        if has_overlap(trees):\n            failed.append(n)\n\n    total_score = float(get_total_score(dict_of_side_length))\n    return {\"total_score\": total_score, \"failed_overlap_n\": failed, \"ok\": (len(failed) == 0)}\n\n\ndef load_groups(filename):\n    groups = {}\n    with open(filename, newline=\"\", encoding=\"utf-8\") as f:\n        reader = csv.reader(f)\n        header = next(reader)\n        for row in reader:\n            full_id = row[0]\n            group = full_id.split(\"_\")[0]\n            groups.setdefault(group, []).append(row)\n    return header, groups\n\n\ndef replace_group(target_file, donor_file, group_id, output_file=None):\n    if output_file is None:\n        output_file = target_file\n\n    header_t, groups_t = load_groups(target_file)\n    _, groups_d = load_groups(donor_file)\n\n    if group_id not in groups_d:\n        raise ValueError(f\"Donor file has no group {group_id}\")\n\n    groups_t[group_id] = groups_d[group_id]\n\n    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n        writer = csv.writer(f)\n        writer.writerow(header_t)\n        for g in sorted(groups_t.keys(), key=lambda x: int(x)):\n            for row in groups_t[g]:\n                writer.writerow(row)\n\n\ndef repair_overlaps_in_place(submission_path, donor_path=BASELINE_CSV):\n    res = score_and_validate_submission(submission_path, max_n=ROT_GROUP_MAX)\n    if res[\"ok\"]:\n        return res\n\n    for n in res[\"failed_overlap_n\"]:\n        replace_group(submission_path, donor_path, f\"{n:03d}\", submission_path)\n\n    # one quick tighten after repair\n    fix_direction(submission_path, submission_path, passes=1)\n    return score_and_validate_submission(submission_path, max_n=ROT_GROUP_MAX)\n\n\n# ============================================================\n# bbox3 runner (fast: parse stdout, only process winners)\n# ============================================================\n\nFINAL_SCORE_RE = re.compile(r\"Final\\s+(?:Total\\s+)?Score:\\s*([0-9]+(?:\\.[0-9]+)?)\")\n\n\ndef parse_bbox3_final_score(stdout: str):\n    m = FINAL_SCORE_RE.search(stdout or \"\")\n    return float(m.group(1)) if m else None\n\n\ndef log(msg):\n    print(msg)\n    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n        f.write(msg + \"\\n\")\n\n\ndef ensure_workspace():\n    os.makedirs(OUT_DIR, exist_ok=True)\n\n    shutil.copy(BASELINE_CSV, WORK_SUBMISSION)\n    shutil.copy(BBOX3_BIN_IN, WORK_BBOX3_BIN)\n    subprocess.run([\"chmod\", \"+x\", WORK_BBOX3_BIN], check=False)\n\n\ndef run_bbox3(timeout_sec, n_value, r_value):\n    return subprocess.run(\n        [WORK_BBOX3_BIN, \"-n\", str(n_value), \"-r\", str(r_value)],\n        capture_output=True,\n        text=True,\n        timeout=int(timeout_sec),\n    )\n\n\ndef save_snapshot(tag):\n    snap = os.path.join(OUT_DIR, f\"{tag}.csv\")\n    shutil.copy(WORK_SUBMISSION, snap)\n    return snap\n\n\ndef fast3h_main():\n    ensure_workspace()\n    start = time.time()\n\n    def time_left():\n        return TOTAL_BUDGET_SEC - (time.time() - start)\n\n    log(\"=\" * 70)\n    log(f\"START {datetime.now().isoformat(timespec='seconds')}\")\n    log(f\"BUDGET {TOTAL_BUDGET_SEC}s (~3h)\")\n    log(\"=\" * 70)\n\n    # Initial tighten + validate once (sets a strong baseline quickly)\n    log(\"Initial fix_direction passes=1 ...\")\n    best_score = fix_direction(WORK_SUBMISSION, WORK_SUBMISSION, passes=1)\n    val0 = repair_overlaps_in_place(WORK_SUBMISSION, donor_path=BASELINE_CSV)\n    best_score = min(best_score, val0[\"total_score\"])\n    best_path = os.path.join(OUT_DIR, \"best_submission.csv\")\n    shutil.copy(WORK_SUBMISSION, best_path)\n    log(f\"Initial best_score = {best_score:.14f} | overlap_ok={val0['ok']}\")\n\n    # ------------------------------------------------------------\n    # 3-hour plan:\n    # Phase A: many short runs to find promising settings (cheap)\n    # Phase B: medium runs on top candidates\n    # Phase C: long runs on the best few\n    # ------------------------------------------------------------\n    phaseA = {\n        \"timeout\": 120,   # 2 min each\n        \"n_values\": [1000, 1200, 1500, 1800, 2000],\n        \"r_values\": [30, 60, 90],\n        \"top_k\": 6,\n        \"fix_passes\": 1,\n    }\n    phaseB = {\n        \"timeout\": 600,   # 10 min each\n        \"top_k\": 3,\n        \"fix_passes\": 2,\n    }\n    phaseC = {\n        \"timeout\": 1200,  # 20 min each\n        \"top_k\": 2,\n        \"fix_passes\": 3,\n    }\n\n    # Store candidates as list of dicts: {\"n\":..., \"r\":..., \"score\":...}\n    candidates = []\n\n    # ---------------- Phase A ----------------\n    log(\"\\n--- PHASE A (short runs) ---\")\n    for r in phaseA[\"r_values\"]:\n        for n in phaseA[\"n_values\"]:\n            if time_left() < 300:  # keep 5 min buffer\n                log(\"Stopping Phase A due to low remaining time.\")\n                break\n\n            log(f\"[A] timeout={phaseA['timeout']} n={n} r={r} | time_left={time_left():.0f}s\")\n\n            try:\n                res = run_bbox3(phaseA[\"timeout\"], n, r)\n            except subprocess.TimeoutExpired:\n                log(f\"[A] TIMEOUT n={n} r={r}\")\n                continue\n\n            bbox_final = parse_bbox3_final_score(res.stdout)\n            if bbox_final is None:\n                log(f\"[A] Could not parse Final Score for n={n} r={r}. Skipping.\")\n                continue\n\n            # Only consider if bbox3 already beats best by a tiny margin\n            if bbox_final < best_score - MIN_IMPROVEMENT_TO_PROCESS:\n                log(f\"[A] Promising: bbox3_final={bbox_final:.14f} < best={best_score:.14f}\")\n                candidates.append({\"n\": n, \"r\": r, \"score\": bbox_final})\n            else:\n                log(f\"[A] Not better: bbox3_final={bbox_final:.14f} best={best_score:.14f}\")\n\n    candidates.sort(key=lambda x: x[\"score\"])\n    candidates = candidates[: phaseA[\"top_k\"]]\n    log(f\"[A] Selected top {len(candidates)} candidates: {candidates}\")\n\n    # Process Phase A winners (run fix + validate only here)\n    for c in list(candidates):\n        if time_left() < 600:\n            log(\"Not enough time to process Phase A winners further.\")\n            break\n\n        log(f\"[A->PROC] n={c['n']} r={c['r']} | fix_passes={phaseA['fix_passes']}\")\n        # re-run bbox3 to regenerate submission for this candidate (ensures file matches)\n        try:\n            run_bbox3(phaseA[\"timeout\"], c[\"n\"], c[\"r\"])\n        except subprocess.TimeoutExpired:\n            continue\n\n        fix_direction(WORK_SUBMISSION, WORK_SUBMISSION, passes=phaseA[\"fix_passes\"])\n        val = repair_overlaps_in_place(WORK_SUBMISSION, donor_path=BASELINE_CSV)\n\n        cur = val[\"total_score\"]\n        save_snapshot(f\"A_n{c['n']}_r{c['r']}_score{cur:.12f}\")\n\n        if val[\"ok\"] and cur < best_score - MIN_IMPROVEMENT_TO_PROCESS:\n            best_score = cur\n            shutil.copy(WORK_SUBMISSION, best_path)\n            log(f\"[A->PROC] NEW BEST = {best_score:.14f}\")\n        else:\n            shutil.copy(best_path, WORK_SUBMISSION)\n\n    # ---------------- Phase B ----------------\n    # Use the (possibly updated) candidates list, but refresh based on best_score\n    candidates.sort(key=lambda x: x[\"score\"])\n    candidates = candidates[: phaseB[\"top_k\"]]\n    log(\"\\n--- PHASE B (medium runs on top candidates) ---\")\n    log(f\"[B] Candidates: {candidates}\")\n\n    for c in candidates:\n        if time_left() < (phaseB[\"timeout\"] + 600):\n            log(\"Stopping Phase B due to low remaining time.\")\n            break\n\n        log(f\"[B] timeout={phaseB['timeout']} n={c['n']} r={c['r']}\")\n        try:\n            res = run_bbox3(phaseB[\"timeout\"], c[\"n\"], c[\"r\"])\n        except subprocess.TimeoutExpired:\n            log(f\"[B] TIMEOUT n={c['n']} r={c['r']}\")\n            continue\n\n        bbox_final = parse_bbox3_final_score(res.stdout) or 1e99\n        if bbox_final >= best_score - MIN_IMPROVEMENT_TO_PROCESS:\n            log(f\"[B] bbox3_final not better ({bbox_final:.14f} vs best {best_score:.14f}), skipping fix/validate.\")\n            shutil.copy(best_path, WORK_SUBMISSION)\n            continue\n\n        fix_direction(WORK_SUBMISSION, WORK_SUBMISSION, passes=phaseB[\"fix_passes\"])\n        val = repair_overlaps_in_place(WORK_SUBMISSION, donor_path=BASELINE_CSV)\n        cur = val[\"total_score\"]\n\n        save_snapshot(f\"B_n{c['n']}_r{c['r']}_score{cur:.12f}\")\n\n        if val[\"ok\"] and cur < best_score - MIN_IMPROVEMENT_TO_PROCESS:\n            best_score = cur\n            shutil.copy(WORK_SUBMISSION, best_path)\n            log(f\"[B] NEW BEST = {best_score:.14f}\")\n        else:\n            shutil.copy(best_path, WORK_SUBMISSION)\n\n    # ---------------- Phase C ----------------\n    log(\"\\n--- PHASE C (long runs on best few) ---\")\n    # Build a small set: take the same candidates, plus a quick neighborhood sweep around best n\n    # (kept small to protect time)\n    base_candidates = candidates[:]\n    extra = []\n    if base_candidates:\n        best_c = base_candidates[0]\n        n0, r0 = best_c[\"n\"], best_c[\"r\"]\n        for dn in (-100, -50, 50, 100):\n            extra.append({\"n\": max(1, n0 + dn), \"r\": r0})\n        for dr in (-10, -5, 5, 10):\n            extra.append({\"n\": n0, \"r\": max(1, r0 + dr)})\n\n    # dedupe\n    seen = set()\n    phaseC_list = []\n    for c in (base_candidates + extra):\n        key = (int(c[\"n\"]), int(c[\"r\"]))\n        if key not in seen:\n            seen.add(key)\n            phaseC_list.append({\"n\": key[0], \"r\": key[1], \"score\": c.get(\"score\", 1e99)})\n\n    phaseC_list = phaseC_list[: phaseC[\"top_k\"]]\n    log(f\"[C] Candidates: {phaseC_list}\")\n\n    for c in phaseC_list:\n        if time_left() < (phaseC[\"timeout\"] + 600):\n            log(\"Stopping Phase C due to low remaining time.\")\n            break\n\n        log(f\"[C] timeout={phaseC['timeout']} n={c['n']} r={c['r']}\")\n        try:\n            res = run_bbox3(phaseC[\"timeout\"], c[\"n\"], c[\"r\"])\n        except subprocess.TimeoutExpired:\n            log(f\"[C] TIMEOUT n={c['n']} r={c['r']}\")\n            continue\n\n        bbox_final = parse_bbox3_final_score(res.stdout) or 1e99\n        if bbox_final >= best_score - MIN_IMPROVEMENT_TO_PROCESS:\n            log(f\"[C] bbox3_final not better ({bbox_final:.14f} vs best {best_score:.14f}), skipping fix/validate.\")\n            shutil.copy(best_path, WORK_SUBMISSION)\n            continue\n\n        fix_direction(WORK_SUBMISSION, WORK_SUBMISSION, passes=phaseC[\"fix_passes\"])\n        val = repair_overlaps_in_place(WORK_SUBMISSION, donor_path=BASELINE_CSV)\n        cur = val[\"total_score\"]\n\n        save_snapshot(f\"C_n{c['n']}_r{c['r']}_score{cur:.12f}\")\n\n        if val[\"ok\"] and cur < best_score - MIN_IMPROVEMENT_TO_PROCESS:\n            best_score = cur\n            shutil.copy(WORK_SUBMISSION, best_path)\n            log(f\"[C] NEW BEST = {best_score:.14f}\")\n        else:\n            shutil.copy(best_path, WORK_SUBMISSION)\n\n    # Finalize\n    shutil.copy(best_path, WORK_SUBMISSION)\n    final_val = score_and_validate_submission(WORK_SUBMISSION, max_n=ROT_GROUP_MAX)\n\n    log(\"\\n\" + \"=\" * 70)\n    log(f\"END {datetime.now().isoformat(timespec='seconds')}\")\n    log(f\"BEST SCORE {best_score:.14f}\")\n    log(f\"FINAL overlap_ok={final_val['ok']} failed={final_val['failed_overlap_n']}\")\n    log(\"=\" * 70)\n\n    # Zip outputs\n    files = glob(\"*.csv\") + glob(\"*.log\") + glob(f\"{OUT_DIR}/*.csv\")\n    zip_name = f\"fast3h_{datetime.now().strftime('%Y-%m-%d-%H-%M')}.zip\"\n    with ZipFile(zip_name, \"w\", compression=ZIP_DEFLATED, compresslevel=9) as z:\n        for fn in files:\n            z.write(fn)\n    print(\"Saved:\", zip_name)\n\n\n# ----------------------------\n# RUN\n# ----------------------------\nfast3h_main()","metadata":{"papermill":{"duration":378.468834,"end_time":"2025-12-20T13:54:28.627593","exception":false,"start_time":"2025-12-20T13:48:10.158759","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T09:22:12.112073Z","iopub.execute_input":"2025-12-23T09:22:12.112244Z","iopub.status.idle":"2025-12-23T09:33:02.45421Z","shell.execute_reply.started":"2025-12-23T09:22:12.112225Z","shell.execute_reply":"2025-12-23T09:33:02.452913Z"}},"outputs":[],"execution_count":null}]}